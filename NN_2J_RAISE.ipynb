{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel du format des données : <br>\n",
    "mains_2J = [preflop, flop, turn, river, proba, small, bigblind,BB, my_stack, stack_J2, my_bet, bet_J2, pot, decision, decision_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des mains à partir des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mains_2J = np.load('mains2J.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un mask pour detecter les all in ( > 4)\n",
    "list_allin_2J = np.where(mains_2J[:,14] > 4)[0]\n",
    "\n",
    "# On supprimer les all-ins : ils seront gérés par un tableau de psuh or fold\n",
    "mains_2J = np.delete(mains_2J, list_allin_2J, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Séparation des 2 classes de raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_raise_2J = np.where(np.logical_and(mains_2J[:,14] > 1, mains_2J[:,14] <= 4 ))[0]\n",
    "\n",
    "\n",
    "mains_2J_onlyraise = mains_2J[list_raise_2J]\n",
    "test_raise_inf_egal2 = np.where(np.logical_and(mains_2J_onlyraise[:,14] > 1,mains_2J_onlyraise[:,14] <= 2.1))[0]\n",
    "test_raise2_4 = np.where(np.logical_and(mains_2J_onlyraise[:,14] > 2.1, mains_2J_onlyraise[:,14] <= 4))[0]\n",
    "\n",
    "mains_2J_onlyraise[test_raise_inf_egal2, 14] = 0  # raise *2.5 \n",
    "mains_2J_onlyraise[test_raise2_4, 14] = 1    # raise *3.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = mains_2J_onlyraise.shape[1]\n",
    "mains_2J_onlyraise_X = mains_2J_onlyraise[:,:(nb_features-2)]\n",
    "mains_2J_onlyraise_Y = mains_2J_onlyraise[:, nb_features-1].squeeze()\n",
    "\n",
    "nb0 = np.where(mains_2J_onlyraise_Y[:] == 0)[0]\n",
    "nb1 = np.where(mains_2J_onlyraise_Y[:] == 1)[0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mains_2J_onlyraise_X[:,[4,7,8,9,10,11,12]])\n",
    "\n",
    "mains_2J_onlyraise_X[:,[4,7,8,9,10,11,12]] = scaler.transform(mains_2J_onlyraise_X[:,[4,7,8,9,10,11,12]])\n",
    "\n",
    "mains_2J_onlyraise_X_train, mains_2J_onlyraise_X_val, mains_2J_onlyraise_Y_train,mains_2J_onlyraise_Y_val = train_test_split(\n",
    "    mains_2J_onlyraise_X, mains_2J_onlyraise_Y, test_size=0.01, stratify=mains_2J_onlyraise_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('mean_var_2J_raise.npz', mean=scaler.mean_, var=scaler.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets et dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainsDataset():\n",
    "    def __init__(self, X, Y):\n",
    "        self.hands= torch.from_numpy(X).type(torch.cuda.DoubleTensor)\n",
    "        self.labels= torch.from_numpy(Y).type(torch.cuda.LongTensor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hand =  self.hands[index]\n",
    "        label =  self.labels[index]\n",
    "        return (hand, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        count = len(self.hands)\n",
    "        return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mains_2J_onlyraise = MainsDataset(mains_2J_onlyraise_X_train, mains_2J_onlyraise_Y_train)\n",
    "train_mains_2J_onlyraise_loader = torch.utils.data.DataLoader(train_mains_2J_onlyraise, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_mains_2J_onlyraise = MainsDataset(mains_2J_onlyraise_X_val, mains_2J_onlyraise_Y_val)\n",
    "val_mains_2J_onlyraise_loader = torch.utils.data.DataLoader(val_mains_2J_onlyraise, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_2J_onlyraise(\n",
      "  (input): Linear(in_features=13, out_features=200, bias=True)\n",
      "  (hidden): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (final): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN_2J_onlyraise(\n",
       "  (input): Linear(in_features=13, out_features=200, bias=True)\n",
       "  (hidden): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (final): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NN_2J_onlyraise(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN_2J_onlyraise, self).__init__()\n",
    "        self.largeur = 200\n",
    "        self.input = nn.Linear(13, self.largeur)\n",
    "        self.hidden = nn.Linear(self.largeur, self.largeur)\n",
    "        self.final = nn.Linear(self.largeur, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "NN_2J_onlyraise = NN_2J_onlyraise()\n",
    "print(NN_2J_onlyraise)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NN_2J_onlyraise.to(device).type(torch.cuda.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du réseau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.001  |  1 loss: 3128.037\n",
      "lr = 0.001  |  2 loss: 3017.711\n",
      "lr = 0.001  |  3 loss: 3101.129\n",
      "lr = 0.001  |  4 loss: 3021.300\n",
      "lr = 0.001  |  5 loss: 3031.281\n",
      "lr = 0.001  |  6 loss: 3110.996\n",
      "lr = 0.001  |  7 loss: 3085.618\n",
      "lr = 0.001  |  8 loss: 3087.717\n",
      "lr = 0.001  |  9 loss: 3069.782\n",
      "lr = 0.001  |  10 loss: 3108.182\n",
      "lr = 0.001  |  11 loss: 3077.700\n",
      "lr = 0.001  |  12 loss: 3112.244\n",
      "lr = 0.001  |  13 loss: 3135.753\n",
      "lr = 0.001  |  14 loss: 3045.965\n",
      "lr = 0.001  |  15 loss: 3004.279\n",
      "lr = 0.001  |  16 loss: 3081.371\n",
      "lr = 0.001  |  17 loss: 3105.648\n",
      "lr = 0.001  |  18 loss: 3087.843\n",
      "lr = 0.001  |  19 loss: 3103.809\n",
      "lr = 0.001  |  20 loss: 3180.034\n",
      "lr = 0.001  |  21 loss: 3017.939\n",
      "lr = 0.001  |  22 loss: 3101.560\n",
      "lr = 0.001  |  23 loss: 3030.764\n",
      "lr = 0.001  |  24 loss: 3142.688\n",
      "lr = 0.001  |  25 loss: 3074.011\n",
      "lr = 0.001  |  26 loss: 3087.457\n",
      "lr = 0.001  |  27 loss: 3106.022\n",
      "lr = 0.001  |  28 loss: 3059.155\n",
      "lr = 0.001  |  29 loss: 3054.402\n",
      "lr = 0.001  |  30 loss: 3095.742\n",
      "lr = 0.001  |  31 loss: 3055.321\n",
      "lr = 0.001  |  32 loss: 3057.205\n",
      "lr = 0.001  |  33 loss: 3084.980\n",
      "lr = 0.001  |  34 loss: 3031.504\n",
      "lr = 0.001  |  35 loss: 3033.695\n",
      "lr = 0.001  |  36 loss: 3037.800\n",
      "lr = 0.001  |  37 loss: 3141.580\n",
      "lr = 0.001  |  38 loss: 3111.610\n",
      "lr = 0.001  |  39 loss: 3017.787\n",
      "lr = 0.001  |  40 loss: 3017.591\n",
      "lr = 0.001  |  41 loss: 3083.730\n",
      "lr = 0.001  |  42 loss: 3068.082\n",
      "lr = 0.001  |  43 loss: 2992.441\n",
      "lr = 0.001  |  44 loss: 3070.934\n",
      "lr = 0.001  |  45 loss: 3193.379\n",
      "lr = 0.001  |  46 loss: 3056.567\n",
      "lr = 0.001  |  47 loss: 3061.803\n",
      "lr = 0.001  |  48 loss: 3066.227\n",
      "lr = 0.001  |  49 loss: 3148.793\n",
      "lr = 0.001  |  50 loss: 3155.607\n",
      "lr = 0.001  |  51 loss: 3035.687\n",
      "lr = 0.001  |  52 loss: 3082.020\n",
      "lr = 0.001  |  53 loss: 3065.306\n",
      "lr = 0.001  |  54 loss: 3054.269\n",
      "lr = 0.001  |  55 loss: 3056.091\n",
      "lr = 0.001  |  56 loss: 3123.774\n",
      "lr = 0.001  |  57 loss: 3051.725\n",
      "lr = 0.001  |  58 loss: 3110.404\n",
      "lr = 0.001  |  59 loss: 3147.574\n",
      "lr = 0.001  |  60 loss: 3125.539\n",
      "lr = 0.001  |  61 loss: 3077.311\n",
      "lr = 0.001  |  62 loss: 3067.621\n",
      "lr = 0.001  |  63 loss: 3039.830\n",
      "lr = 0.001  |  64 loss: 3131.163\n",
      "lr = 0.001  |  65 loss: 3106.594\n",
      "lr = 0.001  |  66 loss: 3073.398\n",
      "lr = 0.001  |  67 loss: 3144.632\n",
      "lr = 0.001  |  68 loss: 3010.016\n",
      "lr = 0.001  |  69 loss: 3078.043\n",
      "lr = 0.001  |  70 loss: 3187.962\n",
      "lr = 0.001  |  71 loss: 3066.382\n",
      "lr = 0.001  |  72 loss: 3078.660\n",
      "lr = 0.001  |  73 loss: 3052.171\n",
      "lr = 0.001  |  74 loss: 3078.494\n",
      "lr = 0.001  |  75 loss: 3109.066\n",
      "lr = 0.001  |  76 loss: 3135.934\n",
      "lr = 0.001  |  77 loss: 3016.046\n",
      "lr = 0.001  |  78 loss: 3057.052\n",
      "lr = 0.001  |  79 loss: 3101.788\n",
      "lr = 0.001  |  80 loss: 3050.783\n",
      "lr = 0.001  |  81 loss: 3019.810\n",
      "lr = 0.001  |  82 loss: 3072.675\n",
      "lr = 0.001  |  83 loss: 3038.670\n",
      "lr = 0.001  |  84 loss: 3173.998\n",
      "lr = 0.001  |  85 loss: 3106.315\n",
      "lr = 0.001  |  86 loss: 3034.453\n",
      "lr = 0.001  |  87 loss: 3093.863\n",
      "lr = 0.001  |  88 loss: 3123.162\n",
      "lr = 0.001  |  89 loss: 3030.558\n",
      "lr = 0.001  |  90 loss: 3069.428\n",
      "lr = 0.001  |  91 loss: 3053.064\n",
      "lr = 0.001  |  92 loss: 3065.114\n",
      "lr = 0.001  |  93 loss: 3103.370\n",
      "lr = 0.001  |  94 loss: 3094.318\n",
      "lr = 0.001  |  95 loss: 3094.660\n",
      "lr = 0.001  |  96 loss: 3099.213\n",
      "lr = 0.001  |  97 loss: 2993.223\n",
      "lr = 0.001  |  98 loss: 3014.536\n",
      "lr = 0.001  |  99 loss: 3063.859\n",
      "lr = 0.001  |  100 loss: 3023.235\n",
      "lr = 0.001  |  101 loss: 3113.170\n",
      "lr = 0.001  |  102 loss: 3040.251\n",
      "lr = 0.001  |  103 loss: 3101.018\n",
      "lr = 0.001  |  104 loss: 3040.027\n",
      "lr = 0.001  |  105 loss: 2990.346\n",
      "lr = 0.001  |  106 loss: 3005.859\n",
      "lr = 0.001  |  107 loss: 3059.887\n",
      "lr = 0.001  |  108 loss: 3127.183\n",
      "lr = 0.001  |  109 loss: 3000.176\n",
      "lr = 0.001  |  110 loss: 3019.348\n",
      "lr = 0.001  |  111 loss: 3134.480\n",
      "lr = 0.001  |  112 loss: 3015.046\n",
      "lr = 0.001  |  113 loss: 3046.670\n",
      "lr = 0.001  |  114 loss: 2977.198\n",
      "lr = 0.001  |  115 loss: 3062.981\n",
      "lr = 0.001  |  116 loss: 3039.187\n",
      "lr = 0.001  |  117 loss: 3042.611\n",
      "lr = 0.001  |  118 loss: 3073.919\n",
      "lr = 0.001  |  119 loss: 3103.477\n",
      "lr = 0.001  |  120 loss: 3106.920\n",
      "lr = 0.001  |  121 loss: 3060.504\n",
      "lr = 0.001  |  122 loss: 3059.357\n",
      "lr = 0.001  |  123 loss: 3021.376\n",
      "lr = 0.001  |  124 loss: 3147.527\n",
      "lr = 0.001  |  125 loss: 3067.229\n",
      "lr = 0.001  |  126 loss: 3118.373\n",
      "lr = 0.001  |  127 loss: 3086.061\n",
      "lr = 0.001  |  128 loss: 3003.353\n",
      "lr = 0.001  |  129 loss: 3085.044\n",
      "lr = 0.001  |  130 loss: 3038.671\n",
      "lr = 0.001  |  131 loss: 3079.989\n",
      "lr = 0.001  |  132 loss: 3085.396\n",
      "lr = 0.001  |  133 loss: 3109.656\n",
      "lr = 0.001  |  134 loss: 3028.882\n",
      "lr = 0.001  |  135 loss: 3076.212\n",
      "lr = 0.001  |  136 loss: 2998.446\n",
      "lr = 0.001  |  137 loss: 3113.288\n",
      "lr = 0.001  |  138 loss: 3001.476\n",
      "lr = 0.001  |  139 loss: 3037.334\n",
      "lr = 0.001  |  140 loss: 3031.232\n",
      "lr = 0.001  |  141 loss: 3031.826\n",
      "lr = 0.001  |  142 loss: 3079.810\n",
      "lr = 0.001  |  143 loss: 3054.143\n",
      "lr = 0.001  |  144 loss: 3086.707\n",
      "lr = 0.001  |  145 loss: 3179.708\n",
      "lr = 0.001  |  146 loss: 3118.807\n",
      "lr = 0.001  |  147 loss: 3074.975\n",
      "lr = 0.001  |  148 loss: 3013.997\n",
      "lr = 0.001  |  149 loss: 3135.065\n",
      "lr = 0.001  |  150 loss: 3086.065\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# lr_tab = [0.1, 0.08, 0.06, 0.04, 0.02, 0.01, 0.005]\n",
    "lr_tab = [0.001]\n",
    "# lr_tab = [0.1, 0.01, 0.005]\n",
    "\n",
    "\n",
    "for lr_ in lr_tab:\n",
    "    \n",
    "    optimizer = optim.SGD(NN_2J_onlyraise.parameters(), lr=lr_)\n",
    "    for epoch in range(150):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_mains_2J_onlyraise_loader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = NN_2J_onlyraise(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        print('lr = %.3f  |  %d loss: %.3f' %(lr_ ,epoch + 1,running_loss*BATCH_SIZE))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network : 91 %\n",
      "Accuracy for each class :\n",
      "2.5 : 94 %\n",
      "3.5 : 81 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "classes = ['2.5', '3.5']\n",
    "class_correct = [0, 0]\n",
    "class_total = [1, 1]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train_mains_2J_onlyraise_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = NN_2J_onlyraise(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print('Accuracy of the network : %d %%' % (100 * correct / total))\n",
    "\n",
    "print('Accuracy for each class :')\n",
    "\n",
    "for i in range(2):\n",
    "    print('%s : %d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    \n",
    "#6 hiddens de 200 : 91% avec 94/81 respctivement (séparation 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du réseau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = NN_2J_onlyraise.state_dict()\n",
    "filename = 'model_theo_2J_onlyraise.pth'\n",
    "torch.save(model_ft, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
